{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAF3F3; padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border:2px solid #E57373; margin-top: 20px;\">\n",
    "    <h1 style=\"font-size:24px; font-family:Georgia, serif; color:#D32F2F; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "        Credit Card Fraud Detection: Model Training and Analysis\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#E6F9E6; padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border:2px solid #66C2A5; margin-top: 20px;\">\n",
    "    <h1 style=\"font-size:24px; font-family:Georgia, serif; color:#4A90E2; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "        About Author\n",
    "    </h1>\n",
    "    <div style=\"text-align:center;\">\n",
    "        <a href=\"https://www.sak.kesug.com\">\n",
    "            <img src=\"https://media.linkedin.com/dms/image/v2/D4E03AQEa6oE6JdFbTQ/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1729333367804?e=1741219200&v=beta&t=gCWp1Yr18TkOP3af6-g-2vsRVJgvkvzbnnusC-YDqUc\" style=\"width: 20%; border-radius: 50%;\" alt=\" Hafiz Kalim Ullah\">\n",
    "        </a>\n",
    "    </div>\n",
    "    <h2 style=\"font-size:20px; font-family:Georgia, serif; color:#333; text-align:center;\">Mr.Hafiz Kalim Ullah</h2>\n",
    "    <p style=\"font-size:16px; font-family:Georgia, serif; line-height: 1.5em; text-align:center; color:#333;\">\n",
    "        <em>Data Scientist / AI Engineer</em><br>\n",
    "        <em>Machine Learning | Deep Learning | NLP | Computer Vision</em>\n",
    "    </p>\n",
    "    <div style=\"text-align:center; margin-top: 10px;\">\n",
    "        <a href=\"https://www.linkedin.com/in/hafizkalimullah/\">\n",
    "            <img width=\"50\" height=\"50\" src=\"https://img.icons8.com/color/48/linkedin.png\" alt=\"linkedin\">\n",
    "        </a>\n",
    "        <a href=\"https://github.com/Kalimullah49\">\n",
    "            <img width=\"50\" height=\"50\" src=\"https://img.icons8.com/ios-glyphs/50/github.png\" alt=\"github\">\n",
    "        </a>\n",
    "        <a href=\"https://www.kaggle.com/hafizkalimullah\">\n",
    "            <img width=\"50\" height=\"50\" src=\"https://img.icons8.com/clouds/100/kaggle.png\" alt=\"kaggle\">\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"text-align:center; margin-top: 20px;\">\n",
    "        <a href=\"https://ww.hku.kesug.com\" style=\"font-size:18px; font-family:Georgia, serif; color:#4A90E2; text-decoration:none; border:2px solid #4A90E2; padding: 5px 15px; border-radius: 5px;\">\n",
    "            Portfolio Site\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D0E6F3; padding: 12px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border:2px solid #66C2A5; margin-top: 12px;\">\n",
    "    <h1 style=\"font-size:28px; font-family:Georgia, serif; color:#000000; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "        Importing Libraries\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Classification models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# importing necessary libraries for model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D0E6F3; padding: 12px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border:2px solid #66C2A5; margin-top: 12px;\">\n",
    "    <h1 style=\"font-size:28px; font-family:Georgia, serif; color:#000000; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "        Loading Dataset\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset which is avail in 6 different files\n",
    "df = pd.DataFrame()\n",
    "for i in range(1, 6):\n",
    "    df = pd.concat([df, pd.read_csv(f\"df = pd.read_csv('../../../../datasets/Projects/Credit Card/credit_card_transactions{i}.csv\")], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D0E6F3; padding: 12px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border:2px solid #66C2A5; margin-top: 12px;\">\n",
    "    <h1 style=\"font-size:28px; font-family:Georgia, serif; color:#000000; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "        Exploratory Data Analysis\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing max clolumns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>merch_zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124521</th>\n",
       "      <td>124521</td>\n",
       "      <td>2019-03-10 14:50:55</td>\n",
       "      <td>30373802285317</td>\n",
       "      <td>fraud_Breitenberg LLC</td>\n",
       "      <td>travel</td>\n",
       "      <td>1.48</td>\n",
       "      <td>Nicholas</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>M</td>\n",
       "      <td>7538 Carrie Meadow Suite 574</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>CA</td>\n",
       "      <td>91711</td>\n",
       "      <td>34.1092</td>\n",
       "      <td>-117.7183</td>\n",
       "      <td>35705</td>\n",
       "      <td>Wellsite geologist</td>\n",
       "      <td>1956-05-15</td>\n",
       "      <td>730b9b59eb21ac457a3414be579e1a5b</td>\n",
       "      <td>1331391055</td>\n",
       "      <td>34.807794</td>\n",
       "      <td>-117.357118</td>\n",
       "      <td>0</td>\n",
       "      <td>92342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186097</th>\n",
       "      <td>1050545</td>\n",
       "      <td>2020-03-11 14:27:33</td>\n",
       "      <td>676102124465</td>\n",
       "      <td>fraud_Gulgowski LLC</td>\n",
       "      <td>home</td>\n",
       "      <td>3.21</td>\n",
       "      <td>Natasha</td>\n",
       "      <td>Mclaughlin</td>\n",
       "      <td>F</td>\n",
       "      <td>8699 Lindsay Ford Apt. 486</td>\n",
       "      <td>Napa</td>\n",
       "      <td>CA</td>\n",
       "      <td>94558</td>\n",
       "      <td>38.4549</td>\n",
       "      <td>-122.2564</td>\n",
       "      <td>94014</td>\n",
       "      <td>Airline pilot</td>\n",
       "      <td>1985-08-21</td>\n",
       "      <td>20b9e56bade116d6fa6eb738eaba01de</td>\n",
       "      <td>1363012053</td>\n",
       "      <td>39.403284</td>\n",
       "      <td>-123.145371</td>\n",
       "      <td>0</td>\n",
       "      <td>95469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49466</th>\n",
       "      <td>265578</td>\n",
       "      <td>2019-05-12 04:09:46</td>\n",
       "      <td>5540636818935089</td>\n",
       "      <td>fraud_Murray-Smitham</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>53.48</td>\n",
       "      <td>Kenneth</td>\n",
       "      <td>Foster</td>\n",
       "      <td>M</td>\n",
       "      <td>329 Michael Extension</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>MA</td>\n",
       "      <td>1843</td>\n",
       "      <td>42.6911</td>\n",
       "      <td>-71.1605</td>\n",
       "      <td>76383</td>\n",
       "      <td>Geoscientist</td>\n",
       "      <td>1985-04-04</td>\n",
       "      <td>f5e5249d5aade2d30bb26d8e528700d3</td>\n",
       "      <td>1336795786</td>\n",
       "      <td>43.201685</td>\n",
       "      <td>-71.799330</td>\n",
       "      <td>0</td>\n",
       "      <td>3242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87222</th>\n",
       "      <td>303334</td>\n",
       "      <td>2019-05-27 13:13:22</td>\n",
       "      <td>2297447006766555</td>\n",
       "      <td>fraud_Schoen-Quigley</td>\n",
       "      <td>kids_pets</td>\n",
       "      <td>38.14</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Walker</td>\n",
       "      <td>F</td>\n",
       "      <td>611 Michael Rue</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>IL</td>\n",
       "      <td>61830</td>\n",
       "      <td>39.9972</td>\n",
       "      <td>-88.6962</td>\n",
       "      <td>478</td>\n",
       "      <td>Landscape architect</td>\n",
       "      <td>1960-01-13</td>\n",
       "      <td>300f9a1039a92fa01d5a14c3c1683163</td>\n",
       "      <td>1338124402</td>\n",
       "      <td>40.193975</td>\n",
       "      <td>-88.424894</td>\n",
       "      <td>0</td>\n",
       "      <td>61853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57099</th>\n",
       "      <td>489323</td>\n",
       "      <td>2019-08-02 05:05:57</td>\n",
       "      <td>213113028819344</td>\n",
       "      <td>fraud_Thiel-Thiel</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>5.82</td>\n",
       "      <td>Melanie</td>\n",
       "      <td>Jimenez</td>\n",
       "      <td>F</td>\n",
       "      <td>77944 Daniels Valley Suite 921</td>\n",
       "      <td>Camden</td>\n",
       "      <td>NY</td>\n",
       "      <td>13316</td>\n",
       "      <td>43.3392</td>\n",
       "      <td>-75.7543</td>\n",
       "      <td>6460</td>\n",
       "      <td>Building control surveyor</td>\n",
       "      <td>1959-09-27</td>\n",
       "      <td>689fc9703b298aab434ad9c5f9b00680</td>\n",
       "      <td>1343883957</td>\n",
       "      <td>43.608979</td>\n",
       "      <td>-76.451536</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "124521      124521   2019-03-10 14:50:55    30373802285317   \n",
       "186097     1050545   2020-03-11 14:27:33      676102124465   \n",
       "49466       265578   2019-05-12 04:09:46  5540636818935089   \n",
       "87222       303334   2019-05-27 13:13:22  2297447006766555   \n",
       "57099       489323   2019-08-02 05:05:57   213113028819344   \n",
       "\n",
       "                     merchant       category    amt     first        last  \\\n",
       "124521  fraud_Breitenberg LLC         travel   1.48  Nicholas     Osborne   \n",
       "186097    fraud_Gulgowski LLC           home   3.21   Natasha  Mclaughlin   \n",
       "49466    fraud_Murray-Smitham    grocery_pos  53.48   Kenneth      Foster   \n",
       "87222    fraud_Schoen-Quigley      kids_pets  38.14     Laura      Walker   \n",
       "57099       fraud_Thiel-Thiel  entertainment   5.82   Melanie     Jimenez   \n",
       "\n",
       "       gender                          street       city state    zip  \\\n",
       "124521      M    7538 Carrie Meadow Suite 574  Claremont    CA  91711   \n",
       "186097      F      8699 Lindsay Ford Apt. 486       Napa    CA  94558   \n",
       "49466       M           329 Michael Extension   Lawrence    MA   1843   \n",
       "87222       F                 611 Michael Rue      Cisco    IL  61830   \n",
       "57099       F  77944 Daniels Valley Suite 921     Camden    NY  13316   \n",
       "\n",
       "            lat      long  city_pop                        job         dob  \\\n",
       "124521  34.1092 -117.7183     35705         Wellsite geologist  1956-05-15   \n",
       "186097  38.4549 -122.2564     94014              Airline pilot  1985-08-21   \n",
       "49466   42.6911  -71.1605     76383               Geoscientist  1985-04-04   \n",
       "87222   39.9972  -88.6962       478        Landscape architect  1960-01-13   \n",
       "57099   43.3392  -75.7543      6460  Building control surveyor  1959-09-27   \n",
       "\n",
       "                               trans_num   unix_time  merch_lat  merch_long  \\\n",
       "124521  730b9b59eb21ac457a3414be579e1a5b  1331391055  34.807794 -117.357118   \n",
       "186097  20b9e56bade116d6fa6eb738eaba01de  1363012053  39.403284 -123.145371   \n",
       "49466   f5e5249d5aade2d30bb26d8e528700d3  1336795786  43.201685  -71.799330   \n",
       "87222   300f9a1039a92fa01d5a14c3c1683163  1338124402  40.193975  -88.424894   \n",
       "57099   689fc9703b298aab434ad9c5f9b00680  1343883957  43.608979  -76.451536   \n",
       "\n",
       "        is_fraud  merch_zipcode  \n",
       "124521         0        92342.0  \n",
       "186097         0        95469.0  \n",
       "49466          0         3242.0  \n",
       "87222          0        61853.0  \n",
       "57099          0            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mid of the df like df.tail() etc\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1080560 entries, 0 to 216111\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1080560 non-null  int64  \n",
      " 1   trans_date_trans_time  1080560 non-null  object \n",
      " 2   cc_num                 1080560 non-null  int64  \n",
      " 3   merchant               1080560 non-null  object \n",
      " 4   category               1080560 non-null  object \n",
      " 5   amt                    1080560 non-null  float64\n",
      " 6   first                  1080560 non-null  object \n",
      " 7   last                   1080560 non-null  object \n",
      " 8   gender                 1080560 non-null  object \n",
      " 9   street                 1080560 non-null  object \n",
      " 10  city                   1080560 non-null  object \n",
      " 11  state                  1080560 non-null  object \n",
      " 12  zip                    1080560 non-null  int64  \n",
      " 13  lat                    1080560 non-null  float64\n",
      " 14  long                   1080560 non-null  float64\n",
      " 15  city_pop               1080560 non-null  int64  \n",
      " 16  job                    1080560 non-null  object \n",
      " 17  dob                    1080560 non-null  object \n",
      " 18  trans_num              1080560 non-null  object \n",
      " 19  unix_time              1080560 non-null  int64  \n",
      " 20  merch_lat              1080560 non-null  float64\n",
      " 21  merch_long             1080560 non-null  float64\n",
      " 22  is_fraud               1080560 non-null  int64  \n",
      " 23  merch_zipcode          917292 non-null   float64\n",
      "dtypes: float64(6), int64(6), object(12)\n",
      "memory usage: 206.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
       "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
       "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
       "       'merch_lat', 'merch_long', 'is_fraud', 'merch_zipcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the unwanted column 'Unnamed: 0'\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080560, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     12\n",
       "float64     6\n",
       "int64       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of object and int64 data types in dataset\n",
    "df.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_date_trans_time    1062107\n",
       "cc_num                       967\n",
       "merchant                     693\n",
       "category                      14\n",
       "amt                        49256\n",
       "first                        349\n",
       "last                         479\n",
       "gender                         2\n",
       "street                       967\n",
       "city                         880\n",
       "state                         51\n",
       "zip                          954\n",
       "lat                          952\n",
       "long                         953\n",
       "city_pop                     866\n",
       "job                          493\n",
       "dob                          952\n",
       "trans_num                1080560\n",
       "unix_time                1062139\n",
       "merch_lat                1046446\n",
       "merch_long               1065948\n",
       "is_fraud                       2\n",
       "merch_zipcode              28250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080560, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_date_trans_time     0.000000\n",
       "cc_num                    0.000000\n",
       "merchant                  0.000000\n",
       "category                  0.000000\n",
       "amt                       0.000000\n",
       "first                     0.000000\n",
       "last                      0.000000\n",
       "gender                    0.000000\n",
       "street                    0.000000\n",
       "city                      0.000000\n",
       "state                     0.000000\n",
       "zip                       0.000000\n",
       "lat                       0.000000\n",
       "long                      0.000000\n",
       "city_pop                  0.000000\n",
       "job                       0.000000\n",
       "dob                       0.000000\n",
       "trans_num                 0.000000\n",
       "unix_time                 0.000000\n",
       "merch_lat                 0.000000\n",
       "merch_long                0.000000\n",
       "is_fraud                  0.000000\n",
       "merch_zipcode            15.109573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the missing values\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As merch_zipcode can not be replaced with mean median mode, so we will drop the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the missing values of merch_zipcode\n",
    "df = df.dropna(subset=['merch_zipcode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_date_trans_time    0.0\n",
       "cc_num                   0.0\n",
       "merchant                 0.0\n",
       "category                 0.0\n",
       "amt                      0.0\n",
       "first                    0.0\n",
       "last                     0.0\n",
       "gender                   0.0\n",
       "street                   0.0\n",
       "city                     0.0\n",
       "state                    0.0\n",
       "zip                      0.0\n",
       "lat                      0.0\n",
       "long                     0.0\n",
       "city_pop                 0.0\n",
       "job                      0.0\n",
       "dob                      0.0\n",
       "trans_num                0.0\n",
       "unix_time                0.0\n",
       "merch_lat                0.0\n",
       "merch_long               0.0\n",
       "is_fraud                 0.0\n",
       "merch_zipcode            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the missing values again\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of dataset after removing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917292, 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means there are no duplicates in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.hist(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#D0E6F3; padding: 12px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border:2px solid #66C2A5; margin-top: 12px;\">\n",
    "    <h1 style=\"font-size:28px; font-family:Georgia, serif; color:#000000; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "        Feature Engineering\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first converting the date column to datetime format\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the year, month, day, hour, and minute from the trans_date_trans_time column\n",
    "df['Year'] = df['trans_date_trans_time'].dt.year\n",
    "df['month'] = df['trans_date_trans_time'].dt.month\n",
    "df['day'] = df['trans_date_trans_time'].dt.day\n",
    "\n",
    "# now dromping the date column\n",
    "df = df.drop('trans_date_trans_time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have now to do the feature selection for the credit card fraud detection dataset, as there are `25` columns here in the dataset, i will apply `feature selection` for both the categorical columns and the numeric columns and then select 5 from categorical columns and top 5 from numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     11\n",
       "float64     6\n",
       "int64       5\n",
       "int32       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will make 2 dataframes one for categories and other for numeric data, to make feature selection easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dataset which include only object data types with is_fraud column included in it\n",
    "cat = df.select_dtypes(include='object')\n",
    "cat['is_fraud'] = df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature          Score\n",
      "10  trans_num  422446.696656\n",
      "9         dob   13425.860589\n",
      "1    category     906.187967\n",
      "2       first     815.387392\n",
      "5      street     128.193842\n",
      "0    merchant      70.616549\n",
      "3        last      65.806407\n",
      "4      gender      22.654473\n",
      "8         job      21.374159\n",
      "7       state      17.304771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'cat' is your DataFrame\n",
    "X = cat.drop('is_fraud', axis=1)\n",
    "y = cat['is_fraud']\n",
    "\n",
    "# Apply Label Encoding to categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Now X contains the encoded categorical features\n",
    "# Apply SelectKBest using the Chi-Square test\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "fit = bestfeatures.fit(X, y)\n",
    "\n",
    "# Making a DataFrame of the scores\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# Concatenate the scores and column names for readability\n",
    "feature_scores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "feature_scores.columns = ['Feature', 'Score']  # Naming the columns\n",
    "print(feature_scores.nlargest(10, 'Score'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature         Score\n",
      "1             amt  45921.191560\n",
      "11          month    180.791909\n",
      "10           Year     35.201484\n",
      "12            day     33.717660\n",
      "6       unix_time     31.121387\n",
      "9   merch_zipcode      5.795172\n",
      "8      merch_long      5.609877\n",
      "4            long      5.469249\n",
      "3             lat      3.367793\n",
      "7       merch_lat      3.176610\n"
     ]
    }
   ],
   "source": [
    "# now using the feature selection for numerical data types\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = num.drop('is_fraud', axis=1)\n",
    "y = num['is_fraud']\n",
    "\n",
    "# Apply SelectKBest using the ANOVA F-value test\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k='all')  # SelectKBest will select the best 'k' features\n",
    "fit = bestfeatures.fit(X, y)\n",
    "\n",
    "# Making a DataFrame of the scores\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# Concatenate the scores and column names for readability\n",
    "feature_scores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "feature_scores.columns = ['Feature', 'Score']  # Naming the columns\n",
    "print(feature_scores.nlargest(10, 'Score'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
